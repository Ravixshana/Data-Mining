# -*- coding: utf-8 -*-
"""LAB03_2020E015.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oqQUV7F0ESAGsgEo84ew2MeKr822mKKr
"""

# Import necessary libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import scipy.stats as stats
import numpy as np
from google.colab import files

# Upload Kaggle credentials
files.upload()

# Setup Kaggle API
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download the dataset using the API
!kaggle datasets download -d gauravduttakiit/smoker-status-prediction-using-biosignals
# Unzipping the downloaded file
!unzip smoker-status-prediction-using-biosignals.zip

# Load the train and test datasets
df_train = pd.read_csv('train_dataset.csv')
df_test = pd.read_csv('test_dataset.csv')

# Add a column to indicate the source of the data
df_train['dataset'] = 'train'
df_test['dataset'] = 'test'

# Combine the two DataFrames
df_combined = pd.concat([df_train, df_test], ignore_index=True)

# Save the combined dataset to a new CSV file
df_combined.to_csv('combined_dataset.csv', index=False)

# Load the combined dataset
df = pd.read_csv('combined_dataset.csv')

# Display basic info
df.info()
df.head()

# Check for missing values
null_counts = df.isnull().sum()
print("Null values in each column:\n", null_counts[null_counts > 0])

# Check for duplicate rows
duplicate_count = df.duplicated().sum()
print(f'Number of duplicate rows: {duplicate_count}')

# Remove duplicate rows
df_cleaned = df.drop_duplicates()

# Check the shape of the cleaned DataFrame
print(f'Original DataFrame shape: {df.shape}')
print(f'Cleaned DataFrame shape: {df_cleaned.shape}')

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Select only numerical columns for outlier visualization
numeric_columns = df_cleaned.select_dtypes(include=[np.number]).columns

# Set up the plotting area
plt.figure(figsize=(15, 10))

# Generate box plots for each numerical feature
for i, col in enumerate(numeric_columns, 1):
    plt.subplot((len(numeric_columns) + 2) // 3, 3, i)
    sns.boxplot(data=df, x=col)
    plt.title(f'Box plot of {col}')

plt.tight_layout()
plt.show()

# Identifying and removing outliers using the IQR method

# Select only numerical columns for outlier detection
numeric_columns = df_cleaned.select_dtypes(include=[np.number]).columns

# Initialize an empty DataFrame to store rows without outliers
df_no_outliers = df_cleaned.copy()

for col in numeric_columns:
    # Calculate Q1 (25th percentile) and Q3 (75th percentile) for the column
    Q1 = df_no_outliers[col].quantile(0.25)
    Q3 = df_no_outliers[col].quantile(0.75)
    IQR = Q3 - Q1

    # Define outlier boundaries
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Remove outliers
    df_no_outliers = df_no_outliers[(df_no_outliers[col] >= lower_bound) & (df_no_outliers[col] <= upper_bound)]

print("Original dataset shape:", df_cleaned.shape)
print("Dataset shape after removing outliers:", df_no_outliers.shape)

# Visualize the dataset after outlier removal
plt.figure(figsize=(15, 10))

# Generate box plots for each numerical feature after outlier removal
for i, col in enumerate(numeric_columns, 1):
    plt.subplot((len(numeric_columns) + 2) // 3, 3, i)
    sns.boxplot(data=df_no_outliers, x=col)
    plt.title(f'Box plot of {col} (Outliers Removed)')

plt.tight_layout()
plt.show()

from sklearn.preprocessing import StandardScaler

# Standardize numerical columns
scaler = StandardScaler()
numeric_cols = df_no_outliers.select_dtypes(include=[np.number]).columns
df_no_outliers[numeric_cols] = scaler.fit_transform(df_no_outliers[numeric_cols])

df_no_outliers.head(10)

# Exclude non-numerical columns
numeric_df = df_no_outliers.select_dtypes(include=[np.number])

# Compute the correlation matrix
correlation_matrix = numeric_df.corr()

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

# Set a threshold for high correlation (e.g., 0.8)
high_correlation_threshold = 0.8
high_corr_features = set()

for i in range(len(correlation_matrix.columns)):
    for j in range(i):
        if abs(correlation_matrix.iloc[i, j]) > high_correlation_threshold:
            high_corr_features.add(correlation_matrix.columns[i])

print("Highly correlated features to remove:", high_corr_features)

# Drop highly correlated features
df_no_outliers = df_no_outliers.drop(columns=high_corr_features)

from sklearn.model_selection import train_test_split

# Drop the 'dataset' column
X = df_no_outliers.drop(columns=['smoking', 'dataset'])  # Replace 'smoking' with the actual target column name
y = df_no_outliers['smoking']

from sklearn.preprocessing import LabelEncoder

# Encode the target variable
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

from sklearn.model_selection import train_test_split

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score
import pandas as pd

# Initialize models
models = {
    'Logistic Regression': LogisticRegression(),
    'Random Forest': RandomForestClassifier(),
    'Gradient Boosting': GradientBoostingClassifier(),
    'SVM': SVC(),
    'K-NN': KNeighborsClassifier(),
    'Naive Bayes': GaussianNB(),
    'Decision Tree': DecisionTreeClassifier()
}

# Initialize an empty list to store results
results = []

# Define a cross-validation function
def evaluate_model(model, X_train, y_train):
    # Use cross-validation to get scores
    accuracy = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy').mean()
    precision = cross_val_score(model, X_train, y_train, cv=5, scoring=make_scorer(precision_score, average='macro')).mean()
    recall = cross_val_score(model, X_train, y_train, cv=5, scoring=make_scorer(recall_score, average='macro')).mean()
    f1 = cross_val_score(model, X_train, y_train, cv=5, scoring=make_scorer(f1_score, average='macro')).mean()

    return accuracy, precision, recall, f1

# Evaluate each model using cross-validation
for name, model in models.items():
    accuracy, precision, recall, f1 = evaluate_model(model, X_train, y_train)

    results.append({
        'Model': name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-score': f1
    })

# Convert results to a DataFrame for easy comparison
results_df = pd.DataFrame(results)
print(results_df)

# Visualize the model comparison
results_df.set_index('Model').plot(kind='bar', figsize=(10, 6))
plt.title('Model Comparison using Cross-validation')
plt.ylabel('Score')
plt.show()